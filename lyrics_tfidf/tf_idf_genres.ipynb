{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyric tf-idf DEA #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Inits, and Method definitions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import importlib\n",
    "\n",
    "import mcnulty_methods\n",
    "import word_utils\n",
    "importlib.reload(mcnulty_methods);\n",
    "importlib.reload(word_utils);\n",
    "from mcnulty_methods import get_formatted_feature_df, get_lyrics_for_tracks\n",
    "from word_utils import get_word_counts, generate_word_charts,get_word_total_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] = 13\n",
    "mpl.rcParams['ytick.labelsize'] = 13\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_term_counts():\n",
    "    term_counts = pd.read_csv('top_artist_terms.csv', index_col='artist_id', names=['artist_id','term', 'term_count'])\n",
    "    term_counts = term_counts[~(term_counts['term'] == 'term')]\n",
    "    del term_counts['term_count']\n",
    "    return term_counts\n",
    "\n",
    "\n",
    "def get_term_counts():\n",
    "    return pd.read_csv('term_counts.csv', names=['term', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Tracks for Particular Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/munozaaron/.local/lib/python3.5/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "conn = create_engine('postgresql://@localhost:5432/mcnulty_songs').raw_connection()\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['hip hop', 'metal']\n",
    "features = get_formatted_feature_df(conn, genres=genres)\n",
    "features.set_index('track_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509969, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>term</th>\n",
       "      <th>duration</th>\n",
       "      <th>music_key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>music_tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRLIPAA128F92F9DD2</th>\n",
       "      <td>Crazy</td>\n",
       "      <td>ARMU0671187B98CBC3</td>\n",
       "      <td>Jamaram</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>244.92363</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.160</td>\n",
       "      <td>1</td>\n",
       "      <td>190.670</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRXPKGE12903CB28C5</th>\n",
       "      <td>Always (Single Edit)</td>\n",
       "      <td>ARYV3RR1187FB52D11</td>\n",
       "      <td>Atlantic Starr</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>239.09832</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.670</td>\n",
       "      <td>1</td>\n",
       "      <td>131.549</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRBNOLI12903CCF8BA</th>\n",
       "      <td>Get Retarded</td>\n",
       "      <td>ART3JP51187FB58279</td>\n",
       "      <td>M.C. A.D.E.</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>346.90567</td>\n",
       "      <td>6</td>\n",
       "      <td>-11.255</td>\n",
       "      <td>0</td>\n",
       "      <td>88.634</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRNXKZP128F426D057</th>\n",
       "      <td>Fiona</td>\n",
       "      <td>ARBPKP01187B9A3888</td>\n",
       "      <td>Bizarra Locomotiva</td>\n",
       "      <td>metal</td>\n",
       "      <td>210.96444</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.761</td>\n",
       "      <td>0</td>\n",
       "      <td>129.999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRZSTBD12903CFC93B</th>\n",
       "      <td>You Don't Wanna Go 2 War (feat. Master P_ C-Mu...</td>\n",
       "      <td>ARKS2FE1187B99325D</td>\n",
       "      <td>Mia X</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>326.66077</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.541</td>\n",
       "      <td>1</td>\n",
       "      <td>155.894</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                title  \\\n",
       "track_id                                                                \n",
       "TRLIPAA128F92F9DD2                                              Crazy   \n",
       "TRXPKGE12903CB28C5                               Always (Single Edit)   \n",
       "TRBNOLI12903CCF8BA                                       Get Retarded   \n",
       "TRNXKZP128F426D057                                              Fiona   \n",
       "TRZSTBD12903CFC93B  You Don't Wanna Go 2 War (feat. Master P_ C-Mu...   \n",
       "\n",
       "                             artist_id         artist_name     term  \\\n",
       "track_id                                                              \n",
       "TRLIPAA128F92F9DD2  ARMU0671187B98CBC3             Jamaram  hip hop   \n",
       "TRXPKGE12903CB28C5  ARYV3RR1187FB52D11      Atlantic Starr  hip hop   \n",
       "TRBNOLI12903CCF8BA  ART3JP51187FB58279         M.C. A.D.E.  hip hop   \n",
       "TRNXKZP128F426D057  ARBPKP01187B9A3888  Bizarra Locomotiva    metal   \n",
       "TRZSTBD12903CFC93B  ARKS2FE1187B99325D               Mia X  hip hop   \n",
       "\n",
       "                     duration music_key  loudness  mode  music_tempo  \\\n",
       "track_id                                                               \n",
       "TRLIPAA128F92F9DD2  244.92363         2    -6.160     1      190.670   \n",
       "TRXPKGE12903CB28C5  239.09832         7    -9.670     1      131.549   \n",
       "TRBNOLI12903CCF8BA  346.90567         6   -11.255     0       88.634   \n",
       "TRNXKZP128F426D057  210.96444         4    -7.761     0      129.999   \n",
       "TRZSTBD12903CFC93B  326.66077         2    -8.541     1      155.894   \n",
       "\n",
       "                    time_signature  \n",
       "track_id                            \n",
       "TRLIPAA128F92F9DD2               4  \n",
       "TRXPKGE12903CB28C5               4  \n",
       "TRBNOLI12903CCF8BA               5  \n",
       "TRNXKZP128F426D057               4  \n",
       "TRZSTBD12903CFC93B               4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Lyrics from Tracks ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_labels = genres\n",
    "unique_words = set()\n",
    "\n",
    "all_lyrics = None\n",
    "hiphop_lyrics = None\n",
    "pop_lyrics = None\n",
    "\n",
    "lyrics_by_genre = dict()\n",
    "remaining_features = features\n",
    "\n",
    "for genre_label in genre_labels:\n",
    "    genre_df = remaining_features[(remaining_features['term'] == genre_label)]\n",
    "    remaining_features = remaining_features[~(remaining_features.index.isin(genre_df.index))]\n",
    "    genre_ids = genre_df.index\n",
    "    \n",
    "    genre_lyrics = get_lyrics_for_tracks(conn, genre_ids)\n",
    "    del genre_lyrics['is_test']\n",
    "    lyrics_by_genre[genre_label] = genre_lyrics\n",
    "        \n",
    "    if all_lyrics is None:\n",
    "        all_lyrics = genre_lyrics\n",
    "    else:\n",
    "        all_lyrics = pd.concat([all_lyrics, genre_lyrics])\n",
    "        \n",
    "    #generate_word_charts(genre_lyrics, genre_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>tf</th>\n",
       "      <th>word_document_count</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRHGIVJ128F93151DB</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>2348</td>\n",
       "      <td>1.748459</td>\n",
       "      <td>0.019646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRLUHWQ128F4288A06</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>2348</td>\n",
       "      <td>1.748459</td>\n",
       "      <td>0.019214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRGYDRO128F92EC219</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>2348</td>\n",
       "      <td>1.748459</td>\n",
       "      <td>0.007702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRCOUZP12903CE6D32</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>2348</td>\n",
       "      <td>1.748459</td>\n",
       "      <td>0.042645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRKXFQZ128F426882F</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>2348</td>\n",
       "      <td>1.748459</td>\n",
       "      <td>0.006857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word  count        tf  word_document_count       idf  \\\n",
       "track_id                                                                  \n",
       "TRHGIVJ128F93151DB    &      1  0.011236                 2348  1.748459   \n",
       "TRLUHWQ128F4288A06    &      2  0.010989                 2348  1.748459   \n",
       "TRGYDRO128F92EC219    &      1  0.004405                 2348  1.748459   \n",
       "TRCOUZP12903CE6D32    &      2  0.024390                 2348  1.748459   \n",
       "TRKXFQZ128F426882F    &      1  0.003922                 2348  1.748459   \n",
       "\n",
       "                      tf_idf  \n",
       "track_id                      \n",
       "TRHGIVJ128F93151DB  0.019646  \n",
       "TRLUHWQ128F4288A06  0.019214  \n",
       "TRGYDRO128F92EC219  0.007702  \n",
       "TRCOUZP12903CE6D32  0.042645  \n",
       "TRKXFQZ128F426882F  0.006857  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tf_calculate(series):\n",
    "    return series / series.count()\n",
    "\n",
    "total_unique_songs = all_lyrics.index.nunique()\n",
    "\n",
    "all_lyrics['tf'] = all_lyrics.groupby('track_id')['count'].transform(lambda x: x / x.sum())\n",
    "all_lyrics['word_document_count'] = all_lyrics.groupby('word')['count'].transform('count')\n",
    "#all_lyrics['idf'] = all_lyrics.groupby('word')['count'].transform(lambda x: total_unique_songs / x.count())\n",
    "\n",
    "all_lyrics['idf'] = np.log10(total_unique_songs / all_lyrics['word_document_count'])\n",
    "all_lyrics['tf_idf'] = all_lyrics['idf'] * all_lyrics['tf']\n",
    "all_lyrics[all_lyrics['word'] == '&'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analysis and Reshaping for Modeling ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection ##\n",
    "\n",
    "Starting with the top x words found per song in the dataset, we'll add features and record the results from our classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_compute_AUC(model, model_name, X,y):\n",
    "    X_val, X_val_test, y_val, y_val_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    model.fit(X_val, y_val)\n",
    "    y_prob = model.predict_proba(X_val_test)[:,1]\n",
    "    auc = roc_auc_score(y_val_test, y_prob)\n",
    "    \n",
    "    return auc\n",
    "    #TODO save these\n",
    "    fpr, tpr, _ = roc_curve(y_val_test, y_prob)\n",
    "    auc = roc_auc_score(y_val_test, y_prob)\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "\n",
    "    x = np.linspace(0,1, 100000)\n",
    "    plt.plot(x, x, linestyle='--')\n",
    "\n",
    "    plt.title('ROC Curve (Pop or Hip Hop)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(['Logistic Regression'])\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_result_df(rows):\n",
    "    test_results = pd.DataFrame(rows, columns=['num_words', 'use_tfidf', 'model','accuracy','precision','recall','f1','auc'])\n",
    "    test_results['accuracy'] = test_results['accuracy'].astype(np.float64)\n",
    "    test_results['use_tfidf'] = test_results['use_tfidf'].astype(np.bool)\n",
    "    test_results['precision'] = test_results['precision'].astype(np.float64)\n",
    "    test_results['recall'] = test_results['recall'].astype(np.float64)\n",
    "    test_results['f1'] = test_results['f1'].astype(np.float64)\n",
    "    test_results['auc'] = test_results['auc'].astype(np.float64)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_df(rows):\n",
    "    test_results = pd.DataFrame(rows, columns=['num_words','use_tfidf','model','feature','importance'])\n",
    "    test_results['use_tfidf'] = test_results['use_tfidf'].astype(np.bool)\n",
    "    test_results['importance'] = test_results['importance'].astype(np.float64)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y(word_sample_size, use_tfidf=False):\n",
    "    word_song_appearance, total_word_appearance = get_word_counts(all_lyrics)\n",
    "\n",
    "    if use_tfidf:\n",
    "        word_song_appearance = get_word_total_idf(all_lyrics)\n",
    "\n",
    "    \n",
    "    word_subset = word_song_appearance.iloc[:word_sample_size]\n",
    "\n",
    "    remaining_lyrics = pd.merge(all_lyrics.reset_index(), word_subset[['word']], how='right', on='word')\n",
    "\n",
    "    remaining_lyrics.set_index('track_id', inplace=True)\n",
    "    if use_tfidf:\n",
    "        del remaining_lyrics['tf']\n",
    "        del remaining_lyrics['word_document_count']\n",
    "        del remaining_lyrics['idf']\n",
    "        pivote_value = 'tf_idf'\n",
    "    else:\n",
    "        pivote_value= 'count'\n",
    "        \n",
    "    tid_lyrics = remaining_lyrics.pivot(columns='word', values=pivote_value)\n",
    "\n",
    "    music_features = ['music_duration','music_key','music_loudness', 'music_mode', 'music_tempo', 'music_time_signature']\n",
    "    \n",
    "    term_only = features[['term']].reset_index().set_index('track_id')\n",
    "    feature_names = list(tid_lyrics.columns)\n",
    "    # complete set,= tid_index -> genre -> word_a -> .... -> word_z\n",
    "    complete_set = pd.merge(term_only, tid_lyrics, left_index=True, right_index=True, how='right')\n",
    "    complete_set.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    y_text = np.asarray(complete_set.iloc[:,0])\n",
    "    y = np.array([1 if val=='hip hop' else 0 for val in y_text])\n",
    "    X = np.asarray(complete_set.iloc[:,1:])\n",
    "\n",
    "    return X,y,feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hip hop    342999\n",
       "metal      166970\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for i in range (0,2):\n",
    "    print('Generating X and y')\n",
    "    X, y, feature_names = get_X_Y(200,use_tfidf=i)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    X_val_fit, X_val_test, y_val_fit, y_val_test = train_test_split(X_val, y_val, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, class_weight={1 : 1, 0 : 2})\n",
    "    print('Fitting Model')\n",
    "    model.fit(X_val_fit, y_val_fit)\n",
    "    print('Predicting Values')\n",
    "    y_test_pred = model.predict(X_val_test)\n",
    "\n",
    "    print('Accuracy: {}'.format(accuracy_score(y_val_test, y_test_pred)))\n",
    "    print('Recall: {}'.format(recall_score(y_val_test, y_test_pred)))\n",
    "    print('Precision: {}'.format(precision_score(y_val_test, y_test_pred)))\n",
    "    print('F1: {}'.format(f1_score(y_val_test, y_test_pred)))''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word sample size: 10\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 20\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 30\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 40\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 50\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 60\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 70\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 80\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 90\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 100\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 110\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 120\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 130\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 140\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 150\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 160\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 170\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 180\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 190\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 200\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 210\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 220\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 230\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 240\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 250\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 260\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 270\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 280\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 290\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 300\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 310\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 320\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 330\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 340\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 350\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 360\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 370\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 380\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 390\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 400\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 410\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 420\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 430\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 440\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 450\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 460\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 470\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 480\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 490\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 500\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 510\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 520\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 530\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 540\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 550\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 560\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 570\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 580\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 590\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 600\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 610\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 620\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 630\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 640\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 650\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 660\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 670\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 680\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 690\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 700\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 710\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 720\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 730\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 740\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 750\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 760\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 770\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 780\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 790\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 800\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 810\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 820\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 830\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 840\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 850\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 860\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 870\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 880\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n",
      "\t\ttree100 score\n",
      "word sample size: 890\n",
      "\tis tfidf: 1\n",
      "\t\tlog fit\n",
      "\t\tlog score\n",
      "\t\ttree100 fit\n"
     ]
    }
   ],
   "source": [
    "word_chunk_size = 10\n",
    "word_upper_bound = 3010\n",
    "# let's stop at 3000 words\n",
    "feat_results = create_feature_df(None)\n",
    "score_results = create_test_result_df(None)\n",
    "\n",
    "tree100 = RandomForestClassifier(n_estimators=100, class_weight={1 : 1, 0 : 2})\n",
    "tree1000 = RandomForestClassifier(n_estimators=1000, class_weight={1 : 1, 0 : 2})\n",
    "tree_models = [tree100]\n",
    "tree_model_names = ['tree100']\n",
    "log_model = LogisticRegression(penalty='l1', class_weight={1 : 1, 0 : 2})\n",
    "\n",
    "\n",
    "output_feature_file_name = 'feature_importance_csvs/feature_importance_results.csv'\n",
    "output_score_file_name = 'feature_importance_csvs/feature_score_results.csv'\n",
    "\n",
    "for word_sample_size in range(10, word_upper_bound, word_chunk_size):\n",
    "    print('word sample size: {}'.format(word_sample_size))\n",
    "    for i in range (1,2):\n",
    "        print('\\tis tfidf: {}'.format(i))\n",
    "        X, y, feature_names = get_X_Y(word_sample_size,use_tfidf=i)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        # For the pandas rows we're generating\n",
    "        number_word_columns = [str(word_sample_size)] * len(feature_names)\n",
    "        tf_idf_columns = [i] * len(feature_names)\n",
    "        \n",
    "        # Handle Logistic Regression\n",
    "        print('\\t\\tlog fit')\n",
    "        log_model.fit(X_val, y_val)\n",
    "        model_columns = ['log'] * len(feature_names)\n",
    "\n",
    "        zipped_features = list(zip(number_word_columns, tf_idf_columns, model_columns, feature_names, log_model.coef_[0]))\n",
    "        new_results = create_feature_df(zipped_features)\n",
    "\n",
    "        # Merge with our results\n",
    "        feat_results = feat_results.append(new_results, ignore_index=True)\n",
    "        feat_results.to_csv(output_feature_file_name)\n",
    "        \n",
    "        print('\\t\\tlog score')\n",
    "        ## handle scores\n",
    "        scoring = {'accuracy': 'accuracy',\n",
    "               'precision': 'precision',\n",
    "               'recall': 'recall',\n",
    "               'f1': 'f1',}\n",
    "        scores = cross_validate(log_model, X_val, y_val, scoring=scoring, cv=5, n_jobs=-1)\n",
    "        accuracy = np.mean(scores['test_accuracy'])\n",
    "        precision = np.mean(scores['test_precision'])\n",
    "        recall = np.mean(scores['test_recall'])\n",
    "        f1 = np.mean(scores['test_f1'])\n",
    "\n",
    "        auc = plot_ROC_compute_AUC(log_model, 'log', X_val, y_val)\n",
    "        \n",
    "        cv_row = [word_sample_size, i, 'log', accuracy, precision, recall, f1, auc]\n",
    "    \n",
    "        score_results = score_results.append(create_test_result_df([cv_row]), ignore_index=True)\n",
    "        score_results.to_csv(output_score_file_name)\n",
    "        \n",
    "        # Now our trees\n",
    "        cv_rows = []\n",
    "        for idx, tree in enumerate(tree_models):\n",
    "            print('\\t\\t{} fit'.format(tree_model_names[idx]))\n",
    "            tree.fit(X_val, y_val)\n",
    "            model_columns = [tree_model_names[idx]] * len(feature_names)\n",
    "            \n",
    "            zipped_features = list(zip(number_word_columns, tf_idf_columns, model_columns, feature_names, tree.feature_importances_))\n",
    "            new_results = create_feature_df(zipped_features)\n",
    "\n",
    "            feat_results = feat_results.append(new_results,\n",
    "                                               ignore_index=True)\n",
    "            feat_results.to_csv(output_feature_file_name)\n",
    "            print('\\t\\t{} score'.format(tree_model_names[idx]))\n",
    "            \n",
    "            scores = cross_validate(tree, X_val, y_val, scoring=scoring, cv=5, n_jobs=-1)\n",
    "            accuracy = np.mean(scores['test_accuracy'])\n",
    "            precision = np.mean(scores['test_precision'])\n",
    "            recall = np.mean(scores['test_recall'])\n",
    "            f1 = np.mean(scores['test_f1'])\n",
    "            \n",
    "            #accuracy = np.mean(cross_val_score(tree, X_val, y_val, cv=5, n_jobs=-1, scoring='accuracy'))\n",
    "            #precision = np.mean(cross_val_score(tree, X_val, y_val, cv=5, n_jobs=-1, scoring='precision'))\n",
    "            #recall = np.mean(cross_val_score(tree, X_val, y_val, cv=5, n_jobs=-1, scoring='recall'))\n",
    "            #f1 = np.mean(cross_val_score(tree, X_val, y_val, cv=5, n_jobs=-1, scoring='f1'))\n",
    "            auc = plot_ROC_compute_AUC(tree, tree_model_names[idx], X_val, y_val)\n",
    "\n",
    "            cv_row = [word_sample_size, i, tree_model_names[idx], accuracy, precision, recall, f1, auc]\n",
    "            cv_rows.append(cv_row)\n",
    "            \n",
    "        score_results = score_results.append(create_test_result_df(cv_rows), ignore_index=True)\n",
    "        score_results.to_csv(output_score_file_name)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist_id": "6817504c0647c2400e2ae907f99cc451",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
