{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyric DEA #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Inits, and Method definitions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import importlib\n",
    "\n",
    "import mcnulty_methods\n",
    "import word_utils\n",
    "importlib.reload(mcnulty_methods);\n",
    "importlib.reload(word_utils);\n",
    "from mcnulty_methods import get_formatted_feature_df, get_lyrics_for_tracks\n",
    "from word_utils import get_word_counts, generate_word_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] = 13\n",
    "mpl.rcParams['ytick.labelsize'] = 13\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_term_counts():\n",
    "    term_counts = pd.read_csv('top_artist_terms.csv', index_col='artist_id', names=['artist_id','term', 'term_count'])\n",
    "    term_counts = term_counts[~(term_counts['term'] == 'term')]\n",
    "    del term_counts['term_count']\n",
    "    return term_counts\n",
    "\n",
    "\n",
    "def get_term_counts():\n",
    "    return pd.read_csv('term_counts.csv', names=['term', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Tracks for Particular Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/munozaaron/.local/lib/python3.5/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "conn = create_engine('postgresql://@localhost:5432/mcnulty_songs').raw_connection()\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_formatted_feature_df(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66730, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>term</th>\n",
       "      <th>duration</th>\n",
       "      <th>music_key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>music_tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12667</th>\n",
       "      <td>Dakar veut du biff</td>\n",
       "      <td>ARQGYAE11F4C846DF6</td>\n",
       "      <td>Alpha 5.20</td>\n",
       "      <td>TRCXTRF128F42845FC</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>161.04444</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.202</td>\n",
       "      <td>1</td>\n",
       "      <td>92.241</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8706</th>\n",
       "      <td>Cock Robin</td>\n",
       "      <td>ARY8MOG1187B999006</td>\n",
       "      <td>Buell Kazee</td>\n",
       "      <td>TRHIBDF128F934D1CA</td>\n",
       "      <td>pop</td>\n",
       "      <td>135.15710</td>\n",
       "      <td>4</td>\n",
       "      <td>-21.793</td>\n",
       "      <td>0</td>\n",
       "      <td>106.008</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61198</th>\n",
       "      <td>More Than This</td>\n",
       "      <td>ARFTXLE122C8675A0A</td>\n",
       "      <td>Mark-Anthony Abel</td>\n",
       "      <td>TRXDNGY12903CA8385</td>\n",
       "      <td>pop</td>\n",
       "      <td>237.66159</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.892</td>\n",
       "      <td>0</td>\n",
       "      <td>141.954</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42581</th>\n",
       "      <td>Everytime I Think Of You</td>\n",
       "      <td>AROVVFJ1269FCD35B6</td>\n",
       "      <td>Marco Borsato / Lucie Silvas</td>\n",
       "      <td>TRLTVHA128F92FEA8F</td>\n",
       "      <td>pop</td>\n",
       "      <td>248.13669</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.909</td>\n",
       "      <td>1</td>\n",
       "      <td>118.253</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56975</th>\n",
       "      <td>Gambling</td>\n",
       "      <td>ARU41P31187B9A6DD3</td>\n",
       "      <td>Samian</td>\n",
       "      <td>TRORWVM128F9323385</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>219.81995</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.076</td>\n",
       "      <td>0</td>\n",
       "      <td>81.389</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title           artist_id  \\\n",
       "12667        Dakar veut du biff  ARQGYAE11F4C846DF6   \n",
       "8706                 Cock Robin  ARY8MOG1187B999006   \n",
       "61198            More Than This  ARFTXLE122C8675A0A   \n",
       "42581  Everytime I Think Of You  AROVVFJ1269FCD35B6   \n",
       "56975                  Gambling  ARU41P31187B9A6DD3   \n",
       "\n",
       "                        artist_name            track_id     term   duration  \\\n",
       "12667                    Alpha 5.20  TRCXTRF128F42845FC  hip hop  161.04444   \n",
       "8706                    Buell Kazee  TRHIBDF128F934D1CA      pop  135.15710   \n",
       "61198             Mark-Anthony Abel  TRXDNGY12903CA8385      pop  237.66159   \n",
       "42581  Marco Borsato / Lucie Silvas  TRLTVHA128F92FEA8F      pop  248.13669   \n",
       "56975                        Samian  TRORWVM128F9323385  hip hop  219.81995   \n",
       "\n",
       "      music_key  loudness  mode  music_tempo  time_signature  \n",
       "12667         9    -5.202     1       92.241               4  \n",
       "8706          4   -21.793     0      106.008               7  \n",
       "61198        11    -4.892     0      141.954               3  \n",
       "42581         0    -4.909     1      118.253               4  \n",
       "56975        11    -4.076     0       81.389               4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Lyrics from Tracks ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_labels = ['hip hop', 'pop']\n",
    "unique_words = set()\n",
    "\n",
    "all_lyrics = None\n",
    "hiphop_lyrics = None\n",
    "pop_lyrics = None\n",
    "\n",
    "for genre_label in genre_labels:\n",
    "    genre_df = features[(features['term'] == genre_label)]\n",
    "\n",
    "    genre_ids = genre_df['track_id']\n",
    "    \n",
    "    genre_lyrics = get_lyrics_for_tracks(conn, genre_ids)\n",
    "    \n",
    "    if genre_label == 'pop':\n",
    "        pop_lyrics = genre_lyrics\n",
    "    elif genre_label == 'hip hop':\n",
    "        hiphop_lyrics = genre_lyrics\n",
    "        \n",
    "    if all_lyrics is None:\n",
    "        all_lyrics = genre_lyrics\n",
    "    else:\n",
    "        all_lyrics = pd.concat([all_lyrics, genre_lyrics])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>like</td>\n",
       "      <td>22699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>know</td>\n",
       "      <td>21079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>love</td>\n",
       "      <td>20439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>get</td>\n",
       "      <td>19670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>got</td>\n",
       "      <td>16060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>go</td>\n",
       "      <td>12534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>oh</td>\n",
       "      <td>11859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>nigga</td>\n",
       "      <td>11441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>see</td>\n",
       "      <td>11026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>one</td>\n",
       "      <td>10963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "2146   like  22699\n",
       "2045   know  21079\n",
       "2213   love  20439\n",
       "1569    get  19670\n",
       "1623    got  16060\n",
       "1607     go  12534\n",
       "2585     oh  11859\n",
       "2519  nigga  11441\n",
       "3267    see  11026\n",
       "2608    one  10963"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_of_words = all_lyrics.groupby('word')['count'].sum().reset_index()\n",
    "\n",
    "total_count_of_words.sort_values('count', ascending=False, inplace=True)\n",
    "\n",
    "total_count_of_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_word_counts = all_lyrics.groupby('track_id')['count'].sum()\n",
    "\n",
    "#track_word_counts.sort_values('count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hip Hop: Analyze per track word counts ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3266.000000\n",
       "mean      176.584507\n",
       "std       109.353813\n",
       "min         1.000000\n",
       "25%        88.000000\n",
       "50%       172.000000\n",
       "75%       246.000000\n",
       "max      2113.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_word_counts = hiphop_lyrics.groupby('track_id')['count'].sum().reset_index()\n",
    "\n",
    "track_word_counts.sort_values('count', ascending=False, inplace=True)\n",
    "\n",
    "track_word_counts['count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pop: Analyze per track word counts ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10224.000000\n",
       "mean       103.895833\n",
       "std         79.404171\n",
       "min          1.000000\n",
       "25%         52.000000\n",
       "50%         83.000000\n",
       "75%        130.000000\n",
       "max       1344.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_word_counts = pop_lyrics.groupby('track_id')['count'].sum().reset_index()\n",
    "\n",
    "track_word_counts.sort_values('count', ascending=False, inplace=True)\n",
    "\n",
    "track_word_counts['count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May want to consider dropping tracks with very few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.set_index('track_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analysis and Reshaping for Modeling ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words: 4324\n",
      "-------------------\n",
      "             count\n",
      "count  4324.000000\n",
      "mean    199.777290\n",
      "std     415.279401\n",
      "min       1.000000\n",
      "25%      40.000000\n",
      "50%      76.000000\n",
      "75%     175.000000\n",
      "max    5888.000000\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "word_song_appearance, total_word_appearance = get_word_counts(all_lyrics)\n",
    "\n",
    "print('Total Unique Words: {}'.format(word_song_appearance.shape[0]))\n",
    "print('-------------------')\n",
    "print(word_song_appearance.describe())\n",
    "print('-------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection ##\n",
    "\n",
    "Starting with the top x words found per song in the dataset, we'll add features and record the results from our classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_compute_AUC(model, model_name, X,y):\n",
    "    X_val, X_val_test, y_val, y_val_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    model.fit(X_val, y_val)\n",
    "    y_prob = model.predict_proba(X_val_test)[:,1]\n",
    "    auc = roc_auc_score(y_val_test, y_prob)\n",
    "    \n",
    "    return auc\n",
    "    #TODO save these\n",
    "    fpr, tpr, _ = roc_curve(y_val_test, y_prob)\n",
    "    auc = roc_auc_score(y_val_test, y_prob)\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "\n",
    "    x = np.linspace(0,1, 100000)\n",
    "    plt.plot(x, x, linestyle='--')\n",
    "\n",
    "    plt.title('ROC Curve (Pop or Hip Hop)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(['Logistic Regression'])\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_result_df(rows):\n",
    "    test_results = pd.DataFrame(rows, columns=['num_words','model','accuracy','precision','recall','f1','auc'])\n",
    "    test_results['accuracy'] = test_results['accuracy'].astype(np.float64)\n",
    "    test_results['precision'] = test_results['precision'].astype(np.float64)\n",
    "    test_results['recall'] = test_results['recall'].astype(np.float64)\n",
    "    test_results['f1'] = test_results['f1'].astype(np.float64)\n",
    "    test_results['auc'] = test_results['auc'].astype(np.float64)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_df(rows):\n",
    "    test_results = pd.DataFrame(rows, columns=['num_words','model','feature','importance'])\n",
    "    test_results['importance'] = test_results['importance'].astype(np.float64)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y(word_sample_size):\n",
    "    word_song_appearance, total_word_appearance = get_word_counts(all_lyrics)\n",
    "    word_subset = word_song_appearance.iloc[:word_sample_size]\n",
    "\n",
    "    remaining_lyrics = pd.merge(all_lyrics.reset_index(), word_subset[['word']], how='right', on='word')\n",
    "\n",
    "    remaining_lyrics.set_index('track_id', inplace=True)\n",
    "    del remaining_lyrics['is_test']\n",
    "    tid_lyrics = remaining_lyrics.pivot(columns='word', values='count')\n",
    "\n",
    "    music_features = ['music_duration','music_key','music_loudness', 'music_mode', 'music_tempo', 'music_time_signature']\n",
    "    \n",
    "    term_only = features[['term'] + music_features].reset_index().set_index('track_id')\n",
    "    feature_names = music_features + list(tid_lyrics.columns)\n",
    "    # complete set,= tid_index -> genre -> word_a -> .... -> word_z\n",
    "    complete_set = pd.merge(term_only, tid_lyrics, left_index=True, right_index=True, how='right')\n",
    "    complete_set.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    y_text = np.asarray(complete_set.iloc[:,0])\n",
    "    y = np.array([1 if val=='hip hop' else 0 for val in y_text])\n",
    "    X = np.asarray(complete_set.iloc[:,1:])\n",
    "\n",
    "    return X,y,feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winning_log_model():\n",
    "    return LogisticRegression(class_weight={1 : 2, 0 : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feature_names = get_X_Y(450)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "X_val_fit, X_val_test, y_val_fit, y_val_test = train_test_split(X_val, y_val, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', class_weight={1 : 2, 0 : 1})\n",
    "\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "model.fit(scaler.fit_transform(X_val_fit), y_val_fit)\n",
    "\n",
    "zipped_features = list(zip(feature_names, model.coef_[0]))\n",
    "zipped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(model, scaler.fit_transform(X_val), y_val, cv=5, n_jobs=-1, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C = np.logspace(0, 10, 30)\n",
    "#grid = GridSearchCV(estimator=get_winning_log_model(),\n",
    "#param_grid=dict(C=C), cv=5, scoring='f1')\n",
    "#grid.fit(scaler.fit_transform(X_val), y_val) # entire datasets were fed here\n",
    "\n",
    "#print ('{},{}'.format(grid.best_params_, grid.best_score_))\n",
    "#for params, mean_score, scores in grid.grid_scores_:\n",
    "#    print ('{},{}'.format(mean_score, params));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.592940252047268"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, class_weight={1 : 2, 0 : 1})\n",
    "\n",
    "np.mean(cross_val_score(model, X_val, y_val, cv=5, n_jobs=-1, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 2},\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_features = list(zip(feature_names, model.feature_importances_))\n",
    "\n",
    "zipped_features.sort(key= lambda x:x[1], reverse=True)\n",
    "#zipped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_chunk_size = 10\n",
    "word_upper_bound = 3010\n",
    "# let's stop at 3000 words\n",
    "feat_results = create_feature_df(None)\n",
    "\n",
    "tree100 = RandomForestClassifier(n_estimators=100, class_weight={1 : 2, 0 : 1})\n",
    "tree1000 = RandomForestClassifier(n_estimators=1000, class_weight={1 : 2, 0 : 1})\n",
    "tree10000 = RandomForestClassifier(n_estimators=10000, class_weight={1 : 2, 0 : 1})\n",
    "tree_models = [tree100, tree1000, tree10000]\n",
    "tree_model_names = ['tree100', 'tree1000', 'tree10000']\n",
    "log_model = LogisticRegression(penalty='l1', class_weight={1 : 2, 0 : 1})\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "zipped_features = list(zip(feature_names, model.coef_[0]))\n",
    "\n",
    "output_file_name = 'cv_files/feature_importance_results.csv'\n",
    "\n",
    "for word_sample_size in range(10, word_upper_bound, word_chunk_size):\n",
    "    X, y, feature_names = get_X_Y(word_sample_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    X_val_fit, X_val_test, y_val_fit, y_val_test = train_test_split(X_val, y_val, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # For the pandas rows we're generating\n",
    "    number_word_columns = [str(word_sample_size)] * len(feature_names)\n",
    "    \n",
    "    # Handle Logistic Regression\n",
    "    log_model.fit(scaler.fit_transform(X_val_fit), y_val_fit)\n",
    "    model_columns = ['log'] * len(feature_names)\n",
    "    \n",
    "    zipped_features = list(zip(number_word_columns, model_columns, feature_names, model.coef_[0]))\n",
    "    new_results = create_feature_df(zipped_features)\n",
    "    \n",
    "    # Merge with our results\n",
    "    feat_results = feat_results.append(new_results, ignore_index=True)\n",
    "    feat_results.to_csv(output_file_name)\n",
    "    \n",
    "    # Now our trees\n",
    "    for idx, tree in enumerate(tree_models):\n",
    "        tree.fit(X_val, y_val)\n",
    "        model_columns = [tree_model_names[idx]] * len(feature_names)\n",
    "        zipped_features = list(zip(number_word_columns, model_columns, feature_names, tree.feature_importances_))\n",
    "        new_results = create_feature_df(zipped_features)\n",
    "        \n",
    "        feat_results = feat_results.append(new_results, ignore_index=True)\n",
    "        feat_results.to_csv(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist_id": "6817504c0647c2400e2ae907f99cc451",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
